{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "def grad( y, x ):\n",
    "    return Lambda( lambda z: K.gradients( z[ 0 ], z[ 1 ] ), output_shape = [1] )( [ y, x ] )\n",
    "\n",
    "def network( i ):\n",
    "    a = Lambda(lambda x: K.log( x + 2 ) )( i )\n",
    "    return a\n",
    "\n",
    "fixed_input = Input(shape=(1,))\n",
    "# double = Input(tensor=tf.Variable( [ 2.0 ] ) )\n",
    "unit_activation = tf.keras.initializers.Ones()\n",
    "dense_dummy_layer = keras.layers.Dense(units=1,use_bias=False,\n",
    "                                      kernel_initializer=unit_activation)(fixed_input)\n",
    "# a = network(fixed_input)\n",
    "a = network(dense_dummy_layer)\n",
    "\n",
    "b = grad( a, fixed_input )\n",
    "c = grad( b, fixed_input )\n",
    "# d = grad( c, fixed_input )\n",
    "# e = grad( d, fixed_input )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1],\n",
    "            [2],\n",
    "            [3]])\n",
    "model = Model( inputs = [ fixed_input], outputs = [ a,b] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               [(None, 1)]          0           lambda[0][0]                     \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1\n",
      "Trainable params: 1\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.0986123],\n",
      "       [1.3862944],\n",
      "       [1.609438 ]], dtype=float32), [array([[0.33333334],\n",
      "       [0.25      ],\n",
      "       [0.2       ]], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "print( model.predict( x, steps = 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0986122886681098 0.3333333333333333 -0.1111111111111111\n",
      "1.3862943611198906 0.25 -0.0625\n",
      "1.6094379124341003 0.2 -0.04\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    print(np.log(i+2),1/(i+2),-1/(i+2)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying new things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "def grad( y, x ):\n",
    "    return Lambda( lambda z: K.gradients( z[ 0 ], z[ 1 ] ))( [ y, x\n",
    "                                                             ] )\n",
    "\n",
    "def network( i ):\n",
    "    a = Lambda(lambda x: K.log( x + 2 ) )( i )\n",
    "    return a\n",
    "\n",
    "fixed_input = Input(shape=(2,))\n",
    "# double = Input(tensor=tf.Variable( [ 2.0 ] ) )\n",
    "unit_activation = tf.keras.initializers.Ones()\n",
    "# dense_dummy_layer = keras.layers.Dense(units=2,use_bias=False,\n",
    "#                                       kernel_initializer=unit_activation)(fixed_input)\n",
    "# a = network(fixed_input)\n",
    "# a = network(dense_dummy_layer)\n",
    "a = Lambda(lambda x: x[:,0]*x[:,1]) (fixed_input)\n",
    "\n",
    "# taking derrivative with respect to secon variable\n",
    "b = keras.layers.Lambda(lambda z: K.gradients(z[0],z[1])) ([a,fixed_input])\n",
    "# c = grad( b, fixed_input )\n",
    "# d = grad( c, fixed_input )\n",
    "# e = grad( d, fixed_input )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,4],\n",
    "            [2,5],\n",
    "            [3,6]])\n",
    "model = Model( inputs = [ fixed_input], outputs = [a, b] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None,)              0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               [(None, 2)]          0           lambda_3[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 4., 10., 18.], dtype=float32), [array([[4., 1.],\n",
      "       [5., 2.],\n",
      "       [6., 3.]], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "print( model.predict( x, steps = 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.09861228866811 0.3333333333333333 -0.1111111111111111\n",
      "3.386294361119891 0.25 -0.0625\n",
      "4.6094379124341005 0.2 -0.04\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    print(np.log(i+2) + i,1/(i+2),-1/(i+2)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "def hes( y, x ):\n",
    "    return Lambda( lambda z: tf.hessians( z[ 0 ], z[ 1 ] ), output_shape = [1] )( [ y, x ] )\n",
    "\n",
    "def network( i ):\n",
    "    a = Lambda(lambda x: K.log( x + 2 ) )( i )\n",
    "    return a\n",
    "\n",
    "fixed_input = Input(shape=(1,))\n",
    "# double = Input(tensor=tf.Variable( [ 2.0 ] ) )\n",
    "unit_activation = tf.keras.initializers.Ones()\n",
    "dense_dummy_layer = keras.layers.Dense(units=1,use_bias=False,\n",
    "                                      kernel_initializer=unit_activation)(fixed_input)\n",
    "# a = network(fixed_input)\n",
    "a = network(dense_dummy_layer)\n",
    "\n",
    "b = hes( a, fixed_input )\n",
    "# c = grad( b, fixed_input )\n",
    "# d = grad( c, fixed_input )\n",
    "# e = grad( d, fixed_input )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1],\n",
    "            [2],\n",
    "            [3]])\n",
    "model = Model( inputs = [ fixed_input], outputs = [b] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               [(None, 1, None, 1)] 0           lambda_5[0][0]                   \n",
      "                                                                 input_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1\n",
      "Trainable params: 1\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[-0.11111112],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.        ],\n",
      "         [-0.0625    ],\n",
      "         [ 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [-0.04      ]]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print( model.predict( x, steps = 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0986122886681098 0.3333333333333333 -0.1111111111111111\n",
      "1.3862943611198906 0.25 -0.0625\n",
      "1.6094379124341003 0.2 -0.04\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    print(np.log(i+2),1/(i+2),-1/(i+2)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything inside a custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.input_layer = Lambda(lambda x: K.log( x+2  ) )\n",
    "\n",
    "    def findGrad(self,func,argm):\n",
    "        return keras.layers.Lambda(lambda x: K.gradients(x[0],x[1])) ([func,argm])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = self.input_layer(inputs)\n",
    "        Z_1 = self.findGrad(Z,inputs)\n",
    "        #     return self.dense2(x)\n",
    "        #     print(\"\\n\\n\\n this is the answer:\",self.square_layer(inputs))\n",
    "        #     print(\"hre is a break\")\n",
    "        return Z_1\n",
    "\n",
    "\n",
    "custom_model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0.],\n",
    "            [1],\n",
    "            [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.5       ],\n",
       "        [0.33333334],\n",
       "        [0.25      ]], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson equation for $x^3$\n",
    "\n",
    "Focus on the findPde layer, input_layer is justa dummy with log in it. IT doesnt matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.input_layer = Lambda(lambda x: K.log( x+2  ) )\n",
    "\n",
    "    def findGrad(self,func,argm):\n",
    "        return keras.layers.Lambda(lambda x: K.gradients(x[0],x[1])[0]) ([func, argm])\n",
    "    \n",
    "    def findPde(self, func, argm):\n",
    "        return keras.layers.Lambda(lambda z: z[0] + 6*z[1]) ([func, argm])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = self.input_layer(inputs)\n",
    "        Z_1 = self.findGrad(Z,inputs)\n",
    "        #     return self.dense2(x)\n",
    "        #     print(\"\\n\\n\\n this is the answer:\",self.square_layer(inputs))\n",
    "        #     print(\"hre is a break\")\n",
    "        return Z_1, self.findPde(Z_1, inputs)\n",
    "\n",
    "\n",
    "custom_model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0.],\n",
    "            [1],\n",
    "            [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(0,3,100).reshape((100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.2529645 ,  7.25296421],\n",
       "       [ 4.88379145,  4.8837914 ],\n",
       "       [ 4.18539667,  4.18539675],\n",
       "       [17.40319252, 17.40319356],\n",
       "       [12.7408371 , 12.74083745],\n",
       "       [ 4.12918663,  4.12918661],\n",
       "       [ 3.71687055,  3.71687053],\n",
       "       [17.87088966, 17.87088889],\n",
       "       [17.31330872, 17.31330776],\n",
       "       [ 4.64755011,  4.64754995],\n",
       "       [13.02423763, 13.02423716],\n",
       "       [12.60574341, 12.60574296],\n",
       "       [16.28721428, 16.28721536],\n",
       "       [10.78253841, 10.78253815],\n",
       "       [ 6.54333973,  6.54333989],\n",
       "       [15.26411533, 15.26411531],\n",
       "       [ 1.69421935,  1.6942193 ],\n",
       "       [16.27932549, 16.27932655],\n",
       "       [ 5.45213509,  5.45213503],\n",
       "       [ 5.33377552,  5.333776  ],\n",
       "       [17.08328056, 17.08328113],\n",
       "       [ 3.71905637,  3.71905622],\n",
       "       [ 8.24392033,  8.24391999],\n",
       "       [ 8.45489979,  8.45489987],\n",
       "       [10.96987629, 10.96987627],\n",
       "       [11.2298708 , 11.22987061],\n",
       "       [ 3.6482358 ,  3.64823556],\n",
       "       [ 0.87971419,  0.87971418],\n",
       "       [15.40541649, 15.40541516],\n",
       "       [13.64494228, 13.64494151],\n",
       "       [ 8.9319706 ,  8.93197014],\n",
       "       [ 1.7726742 ,  1.77267427],\n",
       "       [ 9.52417755,  9.52417814],\n",
       "       [13.65821552, 13.65821612],\n",
       "       [ 0.97897565,  0.97897565],\n",
       "       [15.57763386, 15.57763402],\n",
       "       [ 3.81259537,  3.81259511],\n",
       "       [ 6.56826067,  6.56826094],\n",
       "       [15.29495049, 15.29494968],\n",
       "       [17.47683716, 17.47683716],\n",
       "       [ 6.91833639,  6.91833622],\n",
       "       [12.89989281, 12.89989242],\n",
       "       [ 7.44665384,  7.44665345],\n",
       "       [ 5.82863569,  5.82863552],\n",
       "       [ 7.23907804,  7.23907825],\n",
       "       [11.45480919, 11.45480935],\n",
       "       [17.72266197, 17.72266212],\n",
       "       [ 5.99856853,  5.99856842],\n",
       "       [ 7.93947458,  7.939475  ],\n",
       "       [ 5.99526358,  5.99526322],\n",
       "       [ 1.38482273,  1.38482269],\n",
       "       [11.34746647, 11.3474664 ],\n",
       "       [15.47984219, 15.47984078],\n",
       "       [15.36229992, 15.36230074],\n",
       "       [16.21472168, 16.21472246],\n",
       "       [ 2.83766747,  2.8376674 ],\n",
       "       [14.08207703, 14.08207733],\n",
       "       [11.33205414, 11.33205444],\n",
       "       [14.50984859, 14.50984856],\n",
       "       [10.67259216, 10.67259237],\n",
       "       [ 3.00957942,  3.00957952],\n",
       "       [ 5.61081743,  5.61081749],\n",
       "       [13.49003983, 13.49004033],\n",
       "       [ 9.06373119,  9.06373172],\n",
       "       [16.23819542, 16.23819607],\n",
       "       [14.90906715, 14.90906742],\n",
       "       [17.56385803, 17.56385937],\n",
       "       [ 4.49593163,  4.49593172],\n",
       "       [ 6.0316534 ,  6.03165337],\n",
       "       [ 7.47203493,  7.4720344 ],\n",
       "       [11.48480606, 11.48480685],\n",
       "       [ 2.64348316,  2.64348301],\n",
       "       [ 1.08767414,  1.08767415],\n",
       "       [ 3.73275518,  3.7327552 ],\n",
       "       [ 8.05456161,  8.05456165],\n",
       "       [10.84056568, 10.84056553],\n",
       "       [ 8.80930519,  8.80930554],\n",
       "       [ 7.66508722,  7.66508693],\n",
       "       [ 9.84218311,  9.84218341],\n",
       "       [13.17996216, 13.17996189],\n",
       "       [ 5.30582523,  5.30582564],\n",
       "       [ 0.83118975,  0.83118971],\n",
       "       [ 8.77445316,  8.77445409],\n",
       "       [16.40152931, 16.4015303 ],\n",
       "       [ 6.96909285,  6.96909256],\n",
       "       [ 5.22440434,  5.2244046 ],\n",
       "       [17.12357712, 17.12357831],\n",
       "       [ 8.87623882,  8.87623896],\n",
       "       [ 8.36811638,  8.36811627],\n",
       "       [12.22101212, 12.22101229],\n",
       "       [ 0.95894164,  0.95894164],\n",
       "       [ 7.9176302 ,  7.91762992],\n",
       "       [10.5693531 , 10.56935343],\n",
       "       [15.36271   , 15.36271036],\n",
       "       [15.7578907 , 15.75789035],\n",
       "       [ 3.43266869,  3.43266873],\n",
       "       [ 2.13843012,  2.13843023],\n",
       "       [14.69238949, 14.69239014],\n",
       "       [11.82179832, 11.82179812],\n",
       "       [ 6.83204317,  6.83204343]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([custom_model.predict(x)[1],6*x+custom_model.predict(x)[0]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.47287316],\n",
       "       [1.11661753],\n",
       "       [1.01390593],\n",
       "       [3.07177864],\n",
       "       [2.32758872],\n",
       "       [1.00569458],\n",
       "       [0.94573497],\n",
       "       [3.14700952],\n",
       "       [3.05733027],\n",
       "       [1.08173628],\n",
       "       [2.37246448],\n",
       "       [2.30621647],\n",
       "       [2.89263986],\n",
       "       [2.0191534 ],\n",
       "       [1.36507195],\n",
       "       [2.72891515],\n",
       "       [0.65998244],\n",
       "       [2.8913755 ],\n",
       "       [1.20106488],\n",
       "       [1.1834193 ],\n",
       "       [3.02037074],\n",
       "       [0.94605152],\n",
       "       [1.62470039],\n",
       "       [1.65719982],\n",
       "       [2.04852247],\n",
       "       [2.08933319],\n",
       "       [0.93580237],\n",
       "       [0.54998557],\n",
       "       [2.75149616],\n",
       "       [2.47093912],\n",
       "       [1.73089459],\n",
       "       [0.67075622],\n",
       "       [1.82274892],\n",
       "       [2.47304782],\n",
       "       [0.56319667],\n",
       "       [2.7790321 ],\n",
       "       [0.95961148],\n",
       "       [1.36884347],\n",
       "       [2.73384189],\n",
       "       [3.08361869],\n",
       "       [1.42193567],\n",
       "       [2.35276796],\n",
       "       [1.50243668],\n",
       "       [1.25739057],\n",
       "       [1.4707559 ],\n",
       "       [2.12468794],\n",
       "       [3.12315713],\n",
       "       [1.28290644],\n",
       "       [1.57790765],\n",
       "       [1.28240961],\n",
       "       [0.61778743],\n",
       "       [2.107811  ],\n",
       "       [2.76339418],\n",
       "       [2.744605  ],\n",
       "       [2.88102237],\n",
       "       [0.81964611],\n",
       "       [2.54043672],\n",
       "       [2.10538864],\n",
       "       [2.60855561],\n",
       "       [2.00193194],\n",
       "       [0.84409563],\n",
       "       [1.22476873],\n",
       "       [2.44634071],\n",
       "       [1.75129674],\n",
       "       [2.88478391],\n",
       "       [2.67222125],\n",
       "       [3.09761253],\n",
       "       [1.05942235],\n",
       "       [1.28788075],\n",
       "       [1.50631488],\n",
       "       [2.12940601],\n",
       "       [0.79215862],\n",
       "       [0.57772891],\n",
       "       [0.94803577],\n",
       "       [1.59558155],\n",
       "       [2.02824701],\n",
       "       [1.71191955],\n",
       "       [1.53584445],\n",
       "       [1.87223245],\n",
       "       [2.39714647],\n",
       "       [1.17925677],\n",
       "       [0.54354833],\n",
       "       [1.70653168],\n",
       "       [2.91096454],\n",
       "       [1.42965032],\n",
       "       [1.16714075],\n",
       "       [3.02684389],\n",
       "       [1.7222713 ],\n",
       "       [1.64382467],\n",
       "       [2.24542333],\n",
       "       [0.56052564],\n",
       "       [1.57455496],\n",
       "       [1.98577116],\n",
       "       [2.74467045],\n",
       "       [2.80786901],\n",
       "       [0.90470065],\n",
       "       [0.72135551],\n",
       "       [2.6376556 ],\n",
       "       [2.18245889],\n",
       "       [1.40882942]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + custom_model.predict(x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient of multi-dimensional function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "#         self.input_layer = Lambda(lambda x: K.log(x[:,0:1]+2) + x[:,1:2]**2 * x[:,2:3] + x[:,2:3]**3  )\n",
    "#         self.input_layer = Lambda(lambda x: x[:,0:1] * x[:,1:2] * x[:,2:3]  )\n",
    "        self.input_layer = Lambda(lambda x:x[0]*x[1])\n",
    "#         self.grad_layer = Lambda(lambda x: K.gradients(x[0],x[1][:,0:1]))\n",
    "\n",
    "    def findGrad(self,func,argm):\n",
    "#         x_1 = self.input_copy[:,0:1]\n",
    "# #         x_2 = argm[1]\n",
    "# #         x_3 = argm[2]\n",
    "#         print(\"x_1_type is \",type(x_1))\n",
    "#         print(x_1)\n",
    "        return keras.layers.Lambda(lambda x: tf.gradients(x[0],x[1][0])) ([func,argm])\n",
    "#         return K.gradients(func,argm)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_1,input_2 = inputs\n",
    "        Z = self.input_layer([input_1,input_2])\n",
    "        Z_1 = self.findGrad(Z,inputs)\n",
    "        #     return self.dense2(x)\n",
    "        #     print(\"\\n\\n\\n this is the answer:\",self.square_layer(inputs))\n",
    "        #     print(\"hre is a break\")\n",
    "#         Z_2 = self.findGrad(Z_1,inputs)\n",
    "        return  Z_1\n",
    "\n",
    "\n",
    "custom_model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = np.array([[0.],\n",
    "            [1.],\n",
    "            [2]])\n",
    "x_2 = np.array([[3.],\n",
    "            [4.],\n",
    "            [5]])\n",
    "# x = np.array([0.,1,2])\n",
    "# x = x[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 1), dtype=float32, numpy=\n",
       "array([[[3.],\n",
       "        [4.],\n",
       "        [5.]]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val = custom_model.predict(x=[x_1,x_2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divergence of vector-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "#         self.input_layer = Lambda(lambda x: K.log(x[:,0:1]+2) + x[:,1:2]**2 * x[:,2:3] + x[:,2:3]**3  )\n",
    "#         self.input_layer = Lambda(lambda x: x[:,0:1] * x[:,1:2] * x[:,2:3]  )\n",
    "        self.input_layer = Lambda(lambda x: [10*x[0]**3 + x[1],3*x[1]**2])\n",
    "#         self.grad_layer = Lambda(lambda x: K.gradients(x[0],x[1][:,0:1]))\n",
    "\n",
    "    def findGrad(self,func,argm):\n",
    "#         x_1 = self.input_copy[:,0:1]\n",
    "# #         x_2 = argm[1]\n",
    "# #         x_3 = argm[2]\n",
    "#         print(\"x_1_type is \",type(x_1))\n",
    "#         print(x_1)\n",
    "        return keras.layers.Lambda(lambda x: [tf.gradients(x[0][i],x[1][i]) for i in range(len(argm))]) ([func,argm])\n",
    "#         return K.gradients(func,argm)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_1,input_2 = inputs\n",
    "        Z = self.input_layer([input_1,input_2])\n",
    "        Z_1 = self.findGrad(Z,inputs)\n",
    "        #     return self.dense2(x)\n",
    "        #     print(\"\\n\\n\\n this is the answer:\",self.square_layer(inputs))\n",
    "        #     print(\"hre is a break\")\n",
    "#         Z_2 = self.findGrad(Z_1,inputs)\n",
    "        return  Z_1\n",
    "\n",
    "\n",
    "custom_model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = np.array([[0.],\n",
    "            [1.],\n",
    "            [2]])\n",
    "x_2 = np.array([[3.],\n",
    "            [4.],\n",
    "            [5]])\n",
    "# x = np.array([0.,1,2])\n",
    "# x = x[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[  0.],\n",
       "         [ 30.],\n",
       "         [120.]], dtype=float32)],\n",
       " [array([[18.],\n",
       "         [24.],\n",
       "         [30.]], dtype=float32)]]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val = custom_model.predict(x=[x_1,x_2])\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian of multi-dimensional function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "#         self.input_layer = Lambda(lambda x: K.log(x[:,0:1]+2) + x[:,1:2]**2 * x[:,2:3] + x[:,2:3]**3  )\n",
    "#         self.input_layer = Lambda(lambda x: x[:,0:1] * x[:,1:2] * x[:,2:3]  )\n",
    "#         self.input_layer = Lambda(lambda x: tf.sin(x[0]) + tf.square(x[1])*x[2] + tf.exp(x[2]) )\n",
    "        self.input_layer = Lambda(lambda x: tf.sin(x[:,0:1]) + tf.square(x[:,1:2])*x[:,2:3] + tf.exp(x[:,2:3]) )\n",
    "#         self.grad_layer = Lambda(lambda x: K.gradients(x[0],x[1][:,0:1]))\n",
    "\n",
    "\n",
    "    def findGrad(self,func,argm):\n",
    "        try:\n",
    "            return keras.layers.Lambda(lambda z: [tf.gradients(z[0],x_i,\n",
    "                                                               unconnected_gradients='zero')\n",
    "                                                  for x_i in z[1] ]) ([func,argm])\n",
    "        except Exception as e:\n",
    "            print(\"error occured in find gradient lambda layer of type {} as follows: \".format(type(e)),e)\n",
    "            \n",
    "            \n",
    "    def findSecGrad(self,func,argm):\n",
    "        try:\n",
    "            # list containng diagonal entries of hessian matrix. Note that  tf.gradients \n",
    "            #returns a list of tensors and hence thats why we have  a [0] at the end of  \n",
    "            #the tf.gradients fucntion as tf.gradients(func,argm) [0]\n",
    "            del_sq_layer = keras.layers.Lambda( lambda z: [ tf.gradients(z[0][i], z[1][i],\n",
    "                                                              unconnected_gradients='zero') [0]\n",
    "                                                  for i in range(len(z[1])) ] ) ([func,argm])\n",
    "            return sum(del_sq_layer)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error occured in find laplacian lambda layer of type {} as follows: \".format(type(e)),e)\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_1,input_2,input_3 = inputs\n",
    "#         Z = self.input_layer([input_1, input_2, input_3])\n",
    "        inputs_conc = keras.layers.concatenate(inputs)\n",
    "        Z = self.input_layer(inputs_conc)\n",
    "        Z_1 = self.findGrad(Z,inputs)\n",
    "        #     return self.dense2(x)\n",
    "        #     print(\"\\n\\n\\n this is the answer:\",self.square_layer(inputs))\n",
    "        #     print(\"hre is a break\")\n",
    "        Z_2 = self.findSecGrad(Z_1, inputs)\n",
    "        return  Z_2\n",
    "\n",
    "\n",
    "custom_model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = np.array([[0.],\n",
    "            [1.],\n",
    "            [2],\n",
    "             [4.]  ], dtype=np.float32)\n",
    "x_2 = np.array([[3.],\n",
    "            [4.],\n",
    "            [5],\n",
    "              [6.] ],dtype=np.float32)\n",
    "x_3 = np.array([[9.],\n",
    "            [10.],\n",
    "            [16],\n",
    "             [15]  ],dtype=np.float32)\n",
    "# x = np.array([0.,1,2])\n",
    "# x = x[:,np.newaxis]\n",
    "X = np.concatenate([x_1,x_2,x_3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.1210840e+03],\n",
       "       [2.2045623e+04],\n",
       "       [8.8861420e+06],\n",
       "       [3.2690482e+06]], dtype=float32)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val = custom_model.predict(x=[X[:,0:1],X[:,1:2],X[:,2:3]])\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       "array([[8.1210840e+03],\n",
       "       [2.2045623e+04],\n",
       "       [8.8861420e+06],\n",
       "       [3.2690480e+06]], dtype=float32)>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-tf.sin(x_1)+ 2*x_3 + np.exp(x_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note for finding  gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Can use lambda layers to find gradient with respect to different dimension of input like x,y,z,t.\n",
    "2. If we feed the input as one single block of array(np,tf), then there is problem in using tf.gradients(function,input), since the returned gradient is some kind of sum of gradients in different dim. Please see the tf.gradients() manual.\n",
    "3. A work around will be to feed the different attributes(features) of the data as different inputs so we can find the partial derrivative with respect to each input dim without a problem. Please see the section on graddient of multi-dim function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regarding second gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Seems to be working fine except for some weird instances where None is returned and there is exception thrown while converting this None to a tensor.\n",
    "2. Key point being using the notes above to find the gradient with respect to different input separately and then finally use another lambda layer to find partial derrivative of each of the partial derrivative.\n",
    "3. Regarding the form of the del_sq layer in laplacian:   \n",
    "    Note that  tf.gradients \n",
    "    returns a list of tensors and hence thats why we have  a [0] at the end of  \n",
    "    the tf.gradients fucntion as tf.gradients(func,argm) [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next thing to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporate the lapace layer into the PINN with poission 2d problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
